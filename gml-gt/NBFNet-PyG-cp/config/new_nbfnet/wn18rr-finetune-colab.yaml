output_dir: retrain_dir

dataset:
  class: WN18RR
  root: /storage/ryoji/Graph-Transformer/NBFNet-PyG/datasets/knowledge_graphs/

wandb:
  use: no
  entity: "team_ryoji"
  project: SampleX-WN18RR
  name: NBFNet

model:
  class: NBFNet
  input_dim: 32
  hidden_dims: [32, 32, 32, 32, 32, 32]
  message_func: distmult
  aggregate_func: pna
  short_cut: yes
  layer_norm: yes
  dependent: no
  randomized_edge_drop: 0
  use_pyg_propagation: yes

task:
  num_negative: 32
  strict_negative: yes
  adversarial_temperature: 1
  metric: [mr, mrr, hits@1, hits@3, hits@10]

optimizer:
  class: Adam
  lr: 5.0e-3

eval:
  randomized_edge_drop: [0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]
  eval_on_edge_drop: no
  remove_ground_truth: no
  eval_on_distance_drop: no
  keep_ground_truth: no
  eval_on_train: no
  save_topk: -1 # do not save topk

train:
  gpus: [0,1,2,3]
  batch_size: 16
  num_epoch: 5
  log_interval: 100
  train_on_expl: yes
  train_on_counter_factual: no
  fine_tune_on_val: yes

explainer_eval: # which explanation to evaluate
  eval_mask_type: hard_edge_mask_top_k
  hard_edge_mask_top_k: [10, 25, 50, 75, 100, 300, 500, 1000]
  eval_type: factual_eval
  expl_dir: dir

checkpoint: /storage/ryoji/Graph-Transformer/NBFNet-PyG/checkpoint/explain/wn18rr_dist_eval.pth
